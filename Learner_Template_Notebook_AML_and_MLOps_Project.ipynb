{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klg2JF-oBblG"
      },
      "source": [
        "# Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0CcOjZ-BblL"
      },
      "source": [
        "## **Business Context**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyT6Koe7BblM"
      },
      "source": [
        "\"Visit with Us,\" a leading travel company, is revolutionizing the tourism industry by leveraging data-driven strategies to optimize operations and customer engagement. While introducing a new package offering, such as the Wellness Tourism Package, the company faces challenges in targeting the right customers efficiently. The manual approach to identifying potential customers is inconsistent, time-consuming, and prone to errors, leading to missed opportunities and suboptimal campaign performance.\n",
        "\n",
        "To address these issues, the company aims to implement a scalable and automated system that integrates customer data, predicts potential buyers, and enhances decision-making for marketing strategies. By utilizing an MLOps pipeline, the company seeks to achieve seamless integration of data preprocessing, model development, deployment, and CI/CD practices for continuous improvement. This system will ensure efficient targeting of customers, timely updates to the predictive model, and adaptation to evolving customer behaviors, ultimately driving growth and customer satisfaction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm6bNQOJBblO"
      },
      "source": [
        "## **Objective**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PYtjk_YBblO"
      },
      "source": [
        "As an MLOps Engineer at \"Visit with Us,\" your responsibility is to design and deploy an MLOps pipeline on GitHub to automate the end-to-end workflow for predicting customer purchases. The primary objective is to build a model that predicts whether a customer will purchase the newly introduced Wellness Tourism Package before contacting them. The pipeline will include data cleaning, preprocessing, transformation, model building, training, evaluation, and deployment, ensuring consistent performance and scalability. By leveraging GitHub Actions for CI/CD integration, the system will enable automated updates, streamline model deployment, and improve operational efficiency. This robust predictive solution will empower policymakers to make data-driven decisions, enhance marketing strategies, and effectively target potential customers, thereby driving customer acquisition and business growth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8C11AzTBblP"
      },
      "source": [
        "## **Data Description**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DQx3pkaBblP"
      },
      "source": [
        "The dataset contains customer and interaction data that serve as key attributes for predicting the likelihood of purchasing the Wellness Tourism Package. The detailed attributes are:\n",
        "\n",
        "**Customer Details**\n",
        "- **CustomerID:** Unique identifier for each customer.\n",
        "- **ProdTaken:** Target variable indicating whether the customer has purchased a package (0: No, 1: Yes).\n",
        "- **Age:** Age of the customer.\n",
        "- **TypeofContact:** The method by which the customer was contacted (Company Invited or Self Inquiry).\n",
        "- **CityTier:** The city category based on development, population, and living standards (Tier 1 > Tier 2 > Tier 3).\n",
        "- **Occupation:** Customer's occupation (e.g., Salaried, Freelancer).\n",
        "- **Gender:** Gender of the customer (Male, Female).\n",
        "- **NumberOfPersonVisiting:** Total number of people accompanying the customer on the trip.\n",
        "- **PreferredPropertyStar:** Preferred hotel rating by the customer.\n",
        "- **MaritalStatus:** Marital status of the customer (Single, Married, Divorced).\n",
        "- **NumberOfTrips:** Average number of trips the customer takes annually.\n",
        "- **Passport:** Whether the customer holds a valid passport (0: No, 1: Yes).\n",
        "- **OwnCar:** Whether the customer owns a car (0: No, 1: Yes).\n",
        "- **NumberOfChildrenVisiting:** Number of children below age 5 accompanying the customer.\n",
        "- **Designation:** Customer's designation in their current organization.\n",
        "- **MonthlyIncome:** Gross monthly income of the customer.\n",
        "\n",
        "**Customer Interaction Data**\n",
        "- **PitchSatisfactionScore:** Score indicating the customer's satisfaction with the sales pitch.\n",
        "- **ProductPitched:** The type of product pitched to the customer.\n",
        "- **NumberOfFollowups:** Total number of follow-ups by the salesperson after the sales pitch.-\n",
        "- **DurationOfPitch:** Duration of the sales pitch delivered to the customer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LbSu_p2jYfe"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "giodc4KknHID"
      },
      "outputs": [],
      "source": [
        "# Create a master folder to keep all files created when executing the below code cells\n",
        "import os\n",
        "os.makedirs(\"tourism_project\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SUKPoy0EA4jj"
      },
      "outputs": [],
      "source": [
        "# Create a folder for storing the model building files\n",
        "os.makedirs(\"tourism_project/model_building\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DtS3gNDjBbR"
      },
      "source": [
        "## Data Registration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kNUYcTe-xckI"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"tourism_project/data\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxXiD9ZXxodF"
      },
      "source": [
        "Once the **data** folder created after executing the above cell, please upload the **tourism.csv** in to the folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh2TjRG5WJ4Z"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded from HuggingFace: 4128 rows\n",
            "Starting data cleaning...\n",
            "Missing values before cleaning:\n",
            "Series([], dtype: int64)\n",
            "Missing values after cleaning:\n",
            "Series([], dtype: int64)\n",
            "Feature engineering...\n",
            "Data preprocessing completed! Final shape: (4128, 22)\n",
            "Splitting data...\n",
            "Data split completed!\n",
            "Training set: 3302 samples\n",
            "Test set: 826 samples\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98da0e9eb4804b588b2dcf2598fd30fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1834cace6588409e8976f29d4c28f588",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40f8947599e448ab9791bff64c074431",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "886c04d684a14681a9ed795382359451",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload                         : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84ebede861274be0835b0a6e658c506f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "                                        : 100%|##########|  101kB /  101kB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76e84edb9dc94d0f8e153f9c021e8f02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5eef7d375ef74416bb1828c6217cafdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c2dfeba823c42d0bf29ab04a2abaaf4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51ab98db37094cc687a811ec53239a97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87a67b98b1d348bca08241bcc3d8c975",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload                         : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "347c4ffd8cbc49758ca7956b392bfb4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "                                        : 100%|##########| 29.7kB / 29.7kB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c97497fc1d504a1ba927e94f9f3bb09a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed datasets uploaded to HuggingFace!\n"
          ]
        }
      ],
      "source": [
        "HF_TOKEN = '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'\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from datasets import Dataset, load_dataset\n",
        "\n",
        "# Load data from HuggingFace\n",
        "try:\n",
        "    dataset = load_dataset(\"abhishek-kumar/tourism-package-prediction\", split=\"train\")\n",
        "    df = dataset.to_pandas()\n",
        "    print(f\"Dataset loaded from HuggingFace: {len(df)} rows\")\n",
        "except:\n",
        "    df = pd.read_csv(\"tourism.csv\")\n",
        "    print(f\"Dataset loaded locally: {len(df)} rows\")\n",
        "\n",
        "# Data cleaning and preprocessing\n",
        "print(\"Starting data cleaning...\")\n",
        "\n",
        "# Remove unnecessary columns\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df = df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "# Handle missing values\n",
        "print(\"Missing values before cleaning:\")\n",
        "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
        "\n",
        "# Fill missing values\n",
        "numerical_cols = ['Age', 'DurationOfPitch', 'NumberOfFollowups', 'PreferredPropertyStar', \n",
        "                 'NumberOfTrips', 'PitchSatisfactionScore', 'NumberOfChildrenVisiting', 'MonthlyIncome']\n",
        "\n",
        "for col in numerical_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "categorical_cols = ['TypeofContact', 'Occupation', 'Gender', 'MaritalStatus', \n",
        "                   'ProductPitched', 'Designation']\n",
        "\n",
        "for col in categorical_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else 'Unknown')\n",
        "\n",
        "# Fix data inconsistencies\n",
        "df['Gender'] = df['Gender'].replace('Fe Male', 'Female')\n",
        "\n",
        "print(\"Missing values after cleaning:\")\n",
        "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
        "\n",
        "# Feature engineering\n",
        "print(\"Feature engineering...\")\n",
        "\n",
        "# Create income categories\n",
        "df['IncomeCategory'] = pd.cut(df['MonthlyIncome'], \n",
        "                             bins=[0, 15000, 25000, 35000, float('inf')], \n",
        "                             labels=[0, 1, 2, 3])  # Use numeric labels\n",
        "\n",
        "# Create age groups\n",
        "df['AgeGroup'] = pd.cut(df['Age'], \n",
        "                       bins=[0, 25, 35, 45, 55, float('inf')], \n",
        "                       labels=[0, 1, 2, 3, 4])  # Use numeric labels\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in categorical_columns:\n",
        "    if col != 'CustomerID':\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "\n",
        "print(f\"Data preprocessing completed! Final shape: {df.shape}\")\n",
        "\n",
        "# Split data\n",
        "print(\"Splitting data...\")\n",
        "X = df.drop(['CustomerID', 'ProdTaken'], axis=1)\n",
        "y = df['ProdTaken']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Create train and test dataframes\n",
        "train_df = pd.concat([X_train, y_train], axis=1)\n",
        "test_df = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "# Add CustomerID\n",
        "train_df.insert(0, 'CustomerID', range(300000, 300000 + len(train_df)))\n",
        "test_df.insert(0, 'CustomerID', range(400000, 400000 + len(test_df)))\n",
        "\n",
        "# Save locally\n",
        "train_df.to_csv(\"tourism_project/data/train_data.csv\", index=False)\n",
        "test_df.to_csv(\"tourism_project/data/test_data.csv\", index=False)\n",
        "\n",
        "print(f\"Data split completed!\")\n",
        "print(f\"Training set: {len(train_df)} samples\")\n",
        "print(f\"Test set: {len(test_df)} samples\")\n",
        "\n",
        "# Upload train dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "train_dataset.push_to_hub(\n",
        "    \"abhishek-kumar/tourism-package-prediction-train\",\n",
        "    private=False,\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "\n",
        "# Upload test dataset\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "test_dataset.push_to_hub(\n",
        "    \"abhishek-kumar/tourism-package-prediction-test\",\n",
        "    private=False,\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "print(\"Processed datasets uploaded to HuggingFace!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZZKnLkLjeM4"
      },
      "source": [
        "## Model Training and Registration with Experimentation Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded from HuggingFace\n",
            "Training features shape: (3302, 21)\n",
            "Test features shape: (826, 21)\n",
            "Training Decision Tree...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/31 20:15:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Decision Tree Performance:\n",
            "   Accuracy: 0.8668\n",
            "   Precision: 0.6667\n",
            "   Recall: 0.6164\n",
            "   F1_score: 0.6405\n",
            "   Roc_auc: 0.8710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m2025/08/31 20:15:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Random Forest...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/31 20:15:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Random Forest Performance:\n",
            "   Accuracy: 0.9116\n",
            "   Precision: 0.9216\n",
            "   Recall: 0.5912\n",
            "   F1_score: 0.7203\n",
            "   Roc_auc: 0.9678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m2025/08/31 20:15:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Gradient Boosting...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/31 20:15:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Gradient Boosting Performance:\n",
            "   Accuracy: 0.9395\n",
            "   Precision: 0.9360\n",
            "   Recall: 0.7358\n",
            "   F1_score: 0.8239\n",
            "   Roc_auc: 0.9740\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m2025/08/31 20:15:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/31 20:15:20 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Performance:\n",
            "   Accuracy: 0.9358\n",
            "   Precision: 0.9077\n",
            "   Recall: 0.7421\n",
            "   F1_score: 0.8166\n",
            "   Roc_auc: 0.9588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m2025/08/31 20:15:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training AdaBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/31 20:15:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "AdaBoost Performance:\n",
            "   Accuracy: 0.8584\n",
            "   Precision: 0.7059\n",
            "   Recall: 0.4528\n",
            "   F1_score: 0.5517\n",
            "   Roc_auc: 0.8592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m2025/08/31 20:15:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "MODEL COMPARISON RESULTS\n",
            "============================================================\n",
            "               Model   ROC_AUC\n",
            "0      Decision Tree  0.871046\n",
            "1      Random Forest  0.967842\n",
            "2  Gradient Boosting  0.974004\n",
            "3            XGBoost  0.958766\n",
            "4           AdaBoost  0.859212\n",
            "\n",
            "Best Model: Gradient Boosting (ROC-AUC: 0.9740)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5dcac135076e469e8f29822c21fbc02c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e215b5afd76447bad0fbbc0769f5a2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload                         : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2c7a977abeb400abe4dae83efd4d4da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...ct/model_building/best_model.joblib:  45%|####4     | 1.30MB / 2.89MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model registered to HuggingFace: abhishek-kumar/tourism-package-prediction-model\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from huggingface_hub import HfApi\n",
        "import xgboost as xgb\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import mlflow.xgboost\n",
        "from datasets import load_dataset\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setup MLflow\n",
        "mlflow.set_experiment(\"tourism_package_prediction\")\n",
        "\n",
        "# Load train and test data\n",
        "try:\n",
        "    train_dataset = load_dataset(\"abhishek-kumar/tourism-package-prediction-train\", split=\"train\")\n",
        "    train_df = train_dataset.to_pandas()\n",
        "    test_dataset = load_dataset(\"abhishek-kumar/tourism-package-prediction-test\", split=\"train\")\n",
        "    test_df = test_dataset.to_pandas()\n",
        "    print(\"Data loaded from HuggingFace\")\n",
        "except:\n",
        "    train_df = pd.read_csv(\"tourism_project/data/train_data.csv\")\n",
        "    test_df = pd.read_csv(\"tourism_project/data/test_data.csv\")\n",
        "    print(\"Data loaded locally\")\n",
        "\n",
        "# Prepare features\n",
        "X_train = train_df.drop(['CustomerID', 'ProdTaken'], axis=1)\n",
        "y_train = train_df['ProdTaken']\n",
        "X_test = test_df.drop(['CustomerID', 'ProdTaken'], axis=1)\n",
        "y_test = test_df['ProdTaken']\n",
        "\n",
        "print(f\"Training features shape: {X_train.shape}\")\n",
        "print(f\"Test features shape: {X_test.shape}\")\n",
        "\n",
        "# Function to evaluate models\n",
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
        "    \n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred),\n",
        "        'recall': recall_score(y_test, y_pred),\n",
        "        'f1_score': f1_score(y_test, y_pred),\n",
        "        'roc_auc': roc_auc_score(y_test, y_pred_proba)\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n{model_name} Performance:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"   {metric.capitalize()}: {value:.4f}\")\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "# Train models with hyperparameter tuning\n",
        "models_results = []\n",
        "\n",
        "# 1. Decision Tree\n",
        "print(\"Training Decision Tree...\")\n",
        "with mlflow.start_run(run_name=\"DecisionTree\"):\n",
        "    param_grid = {\n",
        "        'max_depth': [5, 10, 15],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "    \n",
        "    dt = DecisionTreeClassifier(random_state=42)\n",
        "    grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    \n",
        "    best_dt = grid_search.best_estimator_\n",
        "    mlflow.log_params(grid_search.best_params_)\n",
        "    mlflow.log_param(\"model_type\", \"DecisionTree\")\n",
        "    \n",
        "    dt_metrics = evaluate_model(best_dt, X_test, y_test, \"Decision Tree\")\n",
        "    mlflow.log_metrics(dt_metrics)\n",
        "    mlflow.sklearn.log_model(best_dt, \"model\")\n",
        "    \n",
        "    models_results.append((\"Decision Tree\", best_dt, dt_metrics['roc_auc']))\n",
        "\n",
        "# 2. Random Forest\n",
        "print(\"Training Random Forest...\")\n",
        "with mlflow.start_run(run_name=\"RandomForest\"):\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [10, 15, None],\n",
        "        'min_samples_split': [2, 5],\n",
        "        'min_samples_leaf': [1, 2]\n",
        "    }\n",
        "    \n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "    grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    \n",
        "    best_rf = grid_search.best_estimator_\n",
        "    mlflow.log_params(grid_search.best_params_)\n",
        "    mlflow.log_param(\"model_type\", \"RandomForest\")\n",
        "    \n",
        "    rf_metrics = evaluate_model(best_rf, X_test, y_test, \"Random Forest\")\n",
        "    mlflow.log_metrics(rf_metrics)\n",
        "    mlflow.sklearn.log_model(best_rf, \"model\")\n",
        "    \n",
        "    models_results.append((\"Random Forest\", best_rf, rf_metrics['roc_auc']))\n",
        "\n",
        "# 3. Gradient Boosting\n",
        "print(\"Training Gradient Boosting...\")\n",
        "with mlflow.start_run(run_name=\"GradientBoosting\"):\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'learning_rate': [0.05, 0.1, 0.15],\n",
        "        'max_depth': [3, 5, 7]\n",
        "    }\n",
        "    \n",
        "    gb = GradientBoostingClassifier(random_state=42)\n",
        "    grid_search = GridSearchCV(gb, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    \n",
        "    best_gb = grid_search.best_estimator_\n",
        "    mlflow.log_params(grid_search.best_params_)\n",
        "    mlflow.log_param(\"model_type\", \"GradientBoosting\")\n",
        "    \n",
        "    gb_metrics = evaluate_model(best_gb, X_test, y_test, \"Gradient Boosting\")\n",
        "    mlflow.log_metrics(gb_metrics)\n",
        "    mlflow.sklearn.log_model(best_gb, \"model\")\n",
        "    \n",
        "    models_results.append((\"Gradient Boosting\", best_gb, gb_metrics['roc_auc']))\n",
        "\n",
        "# 4. XGBoost\n",
        "print(\"Training XGBoost...\")\n",
        "with mlflow.start_run(run_name=\"XGBoost\"):\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'learning_rate': [0.05, 0.1, 0.15],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'subsample': [0.8, 0.9]\n",
        "    }\n",
        "    \n",
        "    xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "    grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    \n",
        "    best_xgb = grid_search.best_estimator_\n",
        "    mlflow.log_params(grid_search.best_params_)\n",
        "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
        "    \n",
        "    xgb_metrics = evaluate_model(best_xgb, X_test, y_test, \"XGBoost\")\n",
        "    mlflow.log_metrics(xgb_metrics)\n",
        "    mlflow.xgboost.log_model(best_xgb, \"model\")\n",
        "    \n",
        "    models_results.append((\"XGBoost\", best_xgb, xgb_metrics['roc_auc']))\n",
        "\n",
        "# 5. AdaBoost\n",
        "print(\"Training AdaBoost...\")\n",
        "with mlflow.start_run(run_name=\"AdaBoost\"):\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.5, 1.0, 1.5]\n",
        "    }\n",
        "    \n",
        "    ada = AdaBoostClassifier(random_state=42)\n",
        "    grid_search = GridSearchCV(ada, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    \n",
        "    best_ada = grid_search.best_estimator_\n",
        "    mlflow.log_params(grid_search.best_params_)\n",
        "    mlflow.log_param(\"model_type\", \"AdaBoost\")\n",
        "    \n",
        "    ada_metrics = evaluate_model(best_ada, X_test, y_test, \"AdaBoost\")\n",
        "    mlflow.log_metrics(ada_metrics)\n",
        "    mlflow.sklearn.log_model(best_ada, \"model\")\n",
        "    \n",
        "    models_results.append((\"AdaBoost\", best_ada, ada_metrics['roc_auc']))\n",
        "\n",
        "# Compare models and select best\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL COMPARISON RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results_df = pd.DataFrame([(name, score) for name, model, score in models_results], \n",
        "                         columns=['Model', 'ROC_AUC'])\n",
        "print(results_df)\n",
        "\n",
        "# Find best model\n",
        "best_model_name, best_model, best_score = max(models_results, key=lambda x: x[2])\n",
        "print(f\"\\nBest Model: {best_model_name} (ROC-AUC: {best_score:.4f})\")\n",
        "\n",
        "# Save best model\n",
        "os.makedirs(\"tourism_project/model_building\", exist_ok=True)\n",
        "joblib.dump(best_model, \"tourism_project/model_building/best_model.joblib\")\n",
        "\n",
        "# Register best model to HuggingFace\n",
        "api = HfApi()\n",
        "repo_id = \"abhishek-kumar/tourism-package-prediction-model\"\n",
        "\n",
        "try:\n",
        "    api.create_repo(repo_id=repo_id, exist_ok=True, private=False)\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=\"tourism_project/model_building/best_model.joblib\",\n",
        "        path_in_repo=\"best_model.joblib\",\n",
        "        repo_id=repo_id,\n",
        "        token=HF_TOKEN\n",
        "    )\n",
        "    print(f\"Best model registered to HuggingFace: {repo_id}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error registering model: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0McYCZzkji5I"
      },
      "source": [
        "# Deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QrY2v77vbEZ"
      },
      "source": [
        "## Dockerfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0-AMAI72CR-T"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"tourism_project/deployment\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTicTDnPCVZr",
        "outputId": "c63b4416-aa75-46cb-e6b2-3edb3aecbc78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting tourism_project/deployment/Dockerfile\n"
          ]
        }
      ],
      "source": [
        "%%writefile tourism_project/deployment/Dockerfile\n",
        "# Use a minimal base image with Python 3.9 installed\n",
        "FROM python:3.9\n",
        "\n",
        "# Set the working directory inside the container to /app\n",
        "WORKDIR /app\n",
        "\n",
        "# Copy all files from the current directory on the host to the container's /app directory\n",
        "COPY . .\n",
        "\n",
        "# Install Python dependencies listed in requirements.txt\n",
        "RUN pip3 install -r requirements.txt\n",
        "\n",
        "RUN useradd -m -u 1000 user\n",
        "USER user\n",
        "ENV HOME=/home/user \\\n",
        "\tPATH=/home/user/.local/bin:$PATH\n",
        "\n",
        "WORKDIR $HOME/app\n",
        "\n",
        "COPY --chown=user . $HOME/app\n",
        "\n",
        "# Define the command to run the Streamlit app on port \"8501\" and make it accessible externally\n",
        "CMD [\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\", \"--server.enableXsrfProtection=false\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCvrklrBwNvJ"
      },
      "source": [
        "## Streamlit App"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXWe6ObRjP6-"
      },
      "source": [
        "Please ensure that the web app script is named `app.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WBG-jxM89jdp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting tourism_project/deployment/app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile tourism_project/deployment/app.py\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Streamlit App for Tourism Package Prediction\n",
        "\"\"\"\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"Tourism Package Prediction\",\n",
        "    page_icon=\"üèñÔ∏è\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    \"\"\"Load the trained model from HuggingFace Hub\"\"\"\n",
        "    try:\n",
        "        model_path = hf_hub_download(\n",
        "            repo_id=\"abhishek-kumar/tourism-package-prediction-model\",\n",
        "            filename=\"best_model.joblib\"\n",
        "        )\n",
        "        model = joblib.load(model_path)\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading model: {e}\")\n",
        "        return None\n",
        "\n",
        "def prepare_input_data(age, gender, marital_status, city_tier, type_of_contact,\n",
        "                      occupation, designation, monthly_income, num_person_visiting,\n",
        "                      num_children_visiting, preferred_property_star, num_trips,\n",
        "                      passport, own_car, duration_of_pitch, product_pitched,\n",
        "                      num_followups, pitch_satisfaction_score):\n",
        "    \"\"\"Prepare input data for model prediction\"\"\"\n",
        "    \n",
        "    # Create mapping dictionaries\n",
        "    gender_map = {\"Male\": 1, \"Female\": 0}\n",
        "    marital_map = {\"Single\": 2, \"Married\": 1, \"Divorced\": 0, \"Unmarried\": 3}\n",
        "    contact_map = {\"Self Enquiry\": 1, \"Company Invited\": 0}\n",
        "    occupation_map = {\"Salaried\": 2, \"Small Business\": 1, \"Free Lancer\": 0}\n",
        "    designation_map = {\"Executive\": 0, \"Manager\": 1, \"Senior Manager\": 2, \"AVP\": 3, \"VP\": 4}\n",
        "    product_map = {\"Basic\": 0, \"Standard\": 1, \"Deluxe\": 2, \"Super Deluxe\": 3}\n",
        "    passport_map = {\"Yes\": 1, \"No\": 0}\n",
        "    car_map = {\"Yes\": 1, \"No\": 0}\n",
        "    \n",
        "    # Feature engineering (matching training data encoding)\n",
        "    if monthly_income <= 15000:\n",
        "        income_category = 0  # Low\n",
        "    elif monthly_income <= 25000:\n",
        "        income_category = 1  # Medium\n",
        "    elif monthly_income <= 35000:\n",
        "        income_category = 2  # High\n",
        "    else:\n",
        "        income_category = 3  # Very High\n",
        "    \n",
        "    if age <= 25:\n",
        "        age_group = 0  # Young\n",
        "    elif age <= 35:\n",
        "        age_group = 1  # Adult\n",
        "    elif age <= 45:\n",
        "        age_group = 2  # Middle-aged\n",
        "    elif age <= 55:\n",
        "        age_group = 3  # Senior\n",
        "    else:\n",
        "        age_group = 4  # Elderly\n",
        "    \n",
        "    # Create input array\n",
        "    input_array = np.array([[\n",
        "        age, contact_map[type_of_contact], city_tier, duration_of_pitch,\n",
        "        occupation_map[occupation], gender_map[gender], num_person_visiting,\n",
        "        num_followups, product_map[product_pitched], preferred_property_star,\n",
        "        marital_map[marital_status], num_trips, passport_map[passport],\n",
        "        pitch_satisfaction_score, car_map[own_car], num_children_visiting,\n",
        "        designation_map[designation], monthly_income, income_category, age_group\n",
        "    ]])\n",
        "    \n",
        "    return input_array\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main Streamlit app\"\"\"\n",
        "    \n",
        "    st.title(\"Tourism Package Prediction\")\n",
        "    st.markdown(\"### Predict Customer Purchase Likelihood for Wellness Tourism Package\")\n",
        "    st.markdown(\"---\")\n",
        "    \n",
        "    # Load model\n",
        "    model = load_model()\n",
        "    if model is None:\n",
        "        st.error(\"Failed to load the prediction model.\")\n",
        "        return\n",
        "    \n",
        "    # Sidebar inputs\n",
        "    st.sidebar.header(\"Customer Information\")\n",
        "    \n",
        "    # Demographics\n",
        "    st.sidebar.subheader(\"Demographics\")\n",
        "    age = st.sidebar.slider(\"Age\", 18, 80, 35)\n",
        "    gender = st.sidebar.selectbox(\"Gender\", [\"Male\", \"Female\"])\n",
        "    marital_status = st.sidebar.selectbox(\"Marital Status\", [\"Single\", \"Married\", \"Divorced\", \"Unmarried\"])\n",
        "    \n",
        "    # Location & Contact\n",
        "    st.sidebar.subheader(\"Location & Contact\")\n",
        "    city_tier = st.sidebar.selectbox(\"City Tier\", [1, 2, 3])\n",
        "    type_of_contact = st.sidebar.selectbox(\"Type of Contact\", [\"Self Enquiry\", \"Company Invited\"])\n",
        "    \n",
        "    # Professional Info\n",
        "    st.sidebar.subheader(\"Professional Info\")\n",
        "    occupation = st.sidebar.selectbox(\"Occupation\", [\"Salaried\", \"Small Business\", \"Free Lancer\"])\n",
        "    designation = st.sidebar.selectbox(\"Designation\", [\"Executive\", \"Manager\", \"Senior Manager\", \"AVP\", \"VP\"])\n",
        "    monthly_income = st.sidebar.number_input(\"Monthly Income\", 10000, 50000, 20000)\n",
        "    \n",
        "    # Travel Preferences\n",
        "    st.sidebar.subheader(\"Travel Preferences\")\n",
        "    num_person_visiting = st.sidebar.slider(\"Number of Persons Visiting\", 1, 5, 2)\n",
        "    num_children_visiting = st.sidebar.slider(\"Number of Children Visiting\", 0, 3, 0)\n",
        "    preferred_property_star = st.sidebar.slider(\"Preferred Property Star Rating\", 1.0, 5.0, 3.0, 0.5)\n",
        "    num_trips = st.sidebar.slider(\"Number of Trips per Year\", 0.0, 10.0, 2.0, 0.5)\n",
        "    \n",
        "    # Additional Info\n",
        "    st.sidebar.subheader(\"Additional Info\")\n",
        "    passport = st.sidebar.selectbox(\"Has Passport\", [\"Yes\", \"No\"])\n",
        "    own_car = st.sidebar.selectbox(\"Owns Car\", [\"Yes\", \"No\"])\n",
        "    \n",
        "    # Sales Interaction\n",
        "    st.sidebar.subheader(\"Sales Interaction\")\n",
        "    duration_of_pitch = st.sidebar.slider(\"Duration of Pitch (minutes)\", 5, 60, 15)\n",
        "    product_pitched = st.sidebar.selectbox(\"Product Pitched\", [\"Basic\", \"Standard\", \"Deluxe\", \"Super Deluxe\"])\n",
        "    num_followups = st.sidebar.slider(\"Number of Followups\", 0.0, 6.0, 3.0, 0.5)\n",
        "    pitch_satisfaction_score = st.sidebar.slider(\"Pitch Satisfaction Score\", 1, 5, 3)\n",
        "    \n",
        "    # Main content\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "    \n",
        "    with col1:\n",
        "        st.subheader(\"Customer Profile Summary\")\n",
        "        profile_data = {\n",
        "            \"Age\": age,\n",
        "            \"Gender\": gender,\n",
        "            \"Marital Status\": marital_status,\n",
        "            \"City Tier\": city_tier,\n",
        "            \"Occupation\": occupation,\n",
        "            \"Monthly Income\": f\"‚Çπ{monthly_income:,}\",\n",
        "            \"Number of Persons\": num_person_visiting,\n",
        "            \"Preferred Star Rating\": preferred_property_star,\n",
        "            \"Annual Trips\": num_trips,\n",
        "            \"Has Passport\": passport,\n",
        "            \"Owns Car\": own_car\n",
        "        }\n",
        "        \n",
        "        for key, value in profile_data.items():\n",
        "            st.write(f\"**{key}:** {value}\")\n",
        "    \n",
        "    with col2:\n",
        "        st.subheader(\"Prediction\")\n",
        "        \n",
        "        if st.button(\"Predict Purchase Likelihood\", type=\"primary\"):\n",
        "            input_data = prepare_input_data(\n",
        "                age, gender, marital_status, city_tier, type_of_contact,\n",
        "                occupation, designation, monthly_income, num_person_visiting,\n",
        "                num_children_visiting, preferred_property_star, num_trips,\n",
        "                passport, own_car, duration_of_pitch, product_pitched,\n",
        "                num_followups, pitch_satisfaction_score\n",
        "            )\n",
        "            \n",
        "            try:\n",
        "                prediction = model.predict(input_data)[0]\n",
        "                prediction_proba = model.predict_proba(input_data)[0]\n",
        "                \n",
        "                if prediction == 1:\n",
        "                    st.success(\"High likelihood of purchase!\")\n",
        "                    st.write(f\"**Confidence:** {prediction_proba[1]:.2%}\")\n",
        "                    st.balloons()\n",
        "                else:\n",
        "                    st.warning(\"Low likelihood of purchase\")\n",
        "                    st.write(f\"**Confidence:** {prediction_proba[0]:.2%}\")\n",
        "                \n",
        "                # Probability breakdown\n",
        "                st.subheader(\"Probability Breakdown\")\n",
        "                prob_df = pd.DataFrame({\n",
        "                    'Outcome': ['Will Not Purchase', 'Will Purchase'],\n",
        "                    'Probability': [prediction_proba[0], prediction_proba[1]]\n",
        "                })\n",
        "                st.bar_chart(prob_df.set_index('Outcome'))\n",
        "                \n",
        "            except Exception as e:\n",
        "                st.error(f\"Prediction error: {e}\")\n",
        "    \n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### About This Model\")\n",
        "    st.info(\"\"\"\n",
        "    This ML model predicts customer purchase likelihood for the Wellness Tourism Package\n",
        "    based on demographics, travel preferences, and sales interaction data.\n",
        "    \"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07cYzWcIwTL-"
      },
      "source": [
        "## Dependency Handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEgfHL64jU7o"
      },
      "source": [
        "Please ensure that the dependency handling file is named `requirements.txt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nvdmy7Wd9lda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting tourism_project/deployment/requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile tourism_project/deployment/requirements.txt\n",
        "streamlit==1.28.1\n",
        "pandas==2.0.3\n",
        "numpy==1.24.3\n",
        "scikit-learn==1.3.0\n",
        "xgboost==1.7.6\n",
        "joblib==1.3.2\n",
        "huggingface-hub==0.16.4\n",
        "datasets==2.14.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4ynzpKNwWS_"
      },
      "source": [
        "# Hosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7p5sBvTg9nCW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting tourism_project/deployment/deploy_to_hf.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile tourism_project/deployment/deploy_to_hf.py\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Deployment Script for Tourism Package Prediction Project\n",
        "\"\"\"\n",
        "\n",
        "from huggingface_hub import HfApi, login\n",
        "import os\n",
        "\n",
        "#login(token=HF_TOKEN)\n",
        "\n",
        "def deploy_to_huggingface_space():\n",
        "    \"\"\"Deploy application to HuggingFace Spaces\"\"\"\n",
        "    print(\"Deploying to HuggingFace Spaces...\")\n",
        "    \n",
        "    try:\n",
        "        api = HfApi()\n",
        "        space_id = \"abhishek-kumar/tourism_project\"\n",
        "        \n",
        "        files_to_upload = [\n",
        "            (\"app.py\", \"app.py\"),\n",
        "            (\"requirements.txt\", \"requirements.txt\"),\n",
        "            (\"Dockerfile\", \"Dockerfile\")\n",
        "        ]\n",
        "        \n",
        "        print(f\"Uploading files to space: {space_id}\")\n",
        "        \n",
        "        for local_path, repo_path in files_to_upload:\n",
        "            if os.path.exists(local_path):\n",
        "                print(f\"Uploading {local_path}...\")\n",
        "                api.upload_file(\n",
        "                    path_or_fileobj=local_path,\n",
        "                    path_in_repo=repo_path,\n",
        "                    repo_id=space_id,\n",
        "                    repo_type=\"space\",\n",
        "                    token=os.getenv('HF_TOKEN')\n",
        "                )\n",
        "                print(f\"{local_path} uploaded successfully\")\n",
        "        \n",
        "        print(f\"\\nDeployment completed!\")\n",
        "        print(f\"App URL: https://huggingface.co/spaces/{space_id}\")\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Deployment error: {e}\")\n",
        "        return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    deploy_to_huggingface_space()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuCgAW2hktli"
      },
      "source": [
        "# MLOps Pipeline with Github Actions Workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5BZr5i8PKVN"
      },
      "source": [
        "**Note:**\n",
        "\n",
        "1. Before running the file below, make sure to add the HF_TOKEN to your GitHub secrets to enable authentication between GitHub and Hugging Face.\n",
        "2. The below code is for a sample YAML file that can be updated as required to meet the requirements of this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J029tYPq4Rmq"
      },
      "source": [
        "```\n",
        "name: Tourism Project Pipeline\n",
        "\n",
        "on:\n",
        "  push:\n",
        "    branches:\n",
        "      - main  # Automatically triggers on push to the main branch\n",
        "\n",
        "jobs:\n",
        "\n",
        "  register-dataset:\n",
        "    runs-on: ubuntu-latest\n",
        "    steps:\n",
        "      - uses: actions/checkout@v3\n",
        "      - name: Install Dependencies\n",
        "        run: <add_code_here>\n",
        "      - name: Upload Dataset to Hugging Face Hub\n",
        "        env:\n",
        "          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n",
        "        run: <add_code_here>\n",
        "\n",
        "  data-prep:\n",
        "    needs: register-dataset\n",
        "    runs-on: ubuntu-latest\n",
        "    steps:\n",
        "      - uses: actions/checkout@v3\n",
        "      - name: Install Dependencies\n",
        "        run: <add_code_here>\n",
        "      - name: Run Data Preparation\n",
        "        env:\n",
        "          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n",
        "        run: <add_code_here>\n",
        "\n",
        "\n",
        "  model-traning:\n",
        "    needs: data-prep\n",
        "    runs-on: ubuntu-latest\n",
        "    steps:\n",
        "      - uses: actions/checkout@v3\n",
        "      - name: Install Dependencies\n",
        "        run: <add_code_here>\n",
        "      - name: Start MLflow Server\n",
        "        run: |\n",
        "          nohup mlflow ui --host 0.0.0.0 --port 5000 &  # Run MLflow UI in the background\n",
        "          sleep 5  # Wait for a moment to let the server starts\n",
        "      - name: Model Building\n",
        "        env:\n",
        "          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n",
        "        run: <add_code_here>\n",
        "\n",
        "\n",
        "  deploy-hosting:\n",
        "    runs-on: ubuntu-latest\n",
        "    needs: [model-traning,data-prep,register-dataset]\n",
        "    steps:\n",
        "      - uses: actions/checkout@v3\n",
        "      - name: Install Dependencies\n",
        "        run: <add_code_here>\n",
        "      - name: Push files to Frontend Hugging Face Space\n",
        "        env:\n",
        "          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n",
        "        run: <add_code_here>\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9fgZ_Mq3zzp"
      },
      "source": [
        "**Note:** To use this YAML file for our use case, we need to\n",
        "\n",
        "1. Go to the GitHub repository for the project\n",
        "2. Create a folder named ***.github/workflows/***\n",
        "3. In the above folder, create a file named ***pipeline.yml***\n",
        "4. Copy and paste the above content for the YAML file into the ***pipeline.yml*** file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvEUJ-t5kdxH"
      },
      "source": [
        "## Requirements file for the Github Actions Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfqWcLRm-dga"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA6mP-Ebkm3O"
      },
      "source": [
        "## Github Authentication and Push Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T84Ei-g9Z2uw"
      },
      "source": [
        "* Before moving forward, we need to generate a secret token to push files directly from Colab to the GitHub repository.\n",
        "* Please follow the below instructions to create the GitHub token:\n",
        "    - Open your GitHub profile.\n",
        "    - Click on ***Settings***.\n",
        "    - Go to ***Developer Settings***.\n",
        "    - Expand the ***Personal access tokens*** section and select ***Tokens (classic)***.\n",
        "    - Click ***Generate new token***, then choose ***Generate new token (classic)***.\n",
        "    - Add a note and select all required scopes.\n",
        "    - Click ***Generate token***.\n",
        "    - Copy the generated token and store it safely in a notepad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPDx4gqGh7cO"
      },
      "outputs": [],
      "source": [
        "# Install Git\n",
        "!apt-get install git\n",
        "\n",
        "# Set your Git identity (replace with your details)\n",
        "!git config --global user.email \"<-------GitHub Email Address------->\"\n",
        "!git config --global user.name \"<--------GitHub UserName--------->\"\n",
        "\n",
        "# Clone your GitHub repository\n",
        "!git clone https://github.com/<--------GitHub UserName--------->/<--------GitHub Reponame--------->.git\n",
        "\n",
        "# Move your folder to the repository directory\n",
        "!mv /content/tourism_project/ /content/<--------GitHub Reponame--------->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuUahCwVigon"
      },
      "outputs": [],
      "source": [
        "# Change directory to the cloned repository\n",
        "%cd <--------GitHub Reponame--------->/\n",
        "\n",
        "# Add the new folder to Git\n",
        "!git add .\n",
        "\n",
        "# Commit the changes\n",
        "!git commit -m \"first commit\"\n",
        "\n",
        "# Push to GitHub (you'll need your GitHub credentials; use a personal access token if 2FA enabled)\n",
        "!git push https://<--------GitHub UserName--------->:<--------GitHub Token--------->@github.com/<--------GitHub UserName--------->/<--------GitHub Reponame--------->.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-i8Jdyz-_L1"
      },
      "source": [
        "# Output Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTK8Bpda_UHg"
      },
      "source": [
        "- GitHub (link to repository, screenshot of folder structure and executed workflow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qzzesaG_Xw8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KDN31V2_YSr"
      },
      "source": [
        "- Streamlit on Hugging Face (link to HF space, screenshot of Streamlit app)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuIUdj3b_ZYV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN8j9-3nW8G9"
      },
      "source": [
        "<font size=6 color=\"navyblue\">Power Ahead!</font>\n",
        "___"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "klg2JF-oBblG",
        "m0CcOjZ-BblL",
        "zm6bNQOJBblO",
        "z8C11AzTBblP",
        "0LbSu_p2jYfe",
        "9DtS3gNDjBbR",
        "hh2TjRG5WJ4Z",
        "eZZKnLkLjeM4",
        "0McYCZzkji5I",
        "9QrY2v77vbEZ",
        "LCvrklrBwNvJ",
        "07cYzWcIwTL-",
        "V4ynzpKNwWS_",
        "PuCgAW2hktli",
        "PvEUJ-t5kdxH",
        "BA6mP-Ebkm3O",
        "v-i8Jdyz-_L1"
      ],
      "provenance": []
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "applied_stats_project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
